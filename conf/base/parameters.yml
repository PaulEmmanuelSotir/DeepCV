%YAML 1.2
---
# Dataset preprocessing and augmentation YAML configuration file
augmentations_recipes:
  - basic_augmentation: &basic_augmentation
    keep_same_input_shape: true # Whether augmented images will be croped their respective initial input image sizes or not
    random_transform_order: true
    random_transform_ops_range: [1, 4] # An augmentation transform chain can only contain of 1 to 4 augmentation operations
    augmentations_per_image: [1, 3] # Uniform range of augmentation count to be performed per dataset images (thus augmented dataset size will be between 2 and 4 times thez size of original dataset)
    transforms:
      - crop: false
      - brightness: 0.2 # Random brightness variance/severity (assumes pixel data is normalized)
      - contrast: 0.1 # Contrast transform variance/severity
      - tweak_colors: 0.1
      - gamma: 0.05 # gamma tweaking variance/severity
      - posterize: 0.05 # entails conversion of a continuous gradation of tone to several regions of fewer tones
      - noise: 0.1
      - rotate: [-0.4, 0.4] # e.g., `[-|a|, |b|]` rotation range means random rotation will be sampled from a gaussian distribution truncated between -180x|a|° and 180x|b|°, with gaussian variance beeing proportional to `|a|-|b|`
      - translate: 0.2 # variance/severity of image translation transform
      - scale: 0.2
      - smooth_non_linear_deformation: false # Strenght/severity of a non-linear image deformation (set to null, false or 0 to disable)
  - mixed_augmentation:
    mixing:
      - mix_transform_chains_count: 3  # An augmented image will be the result of a mix of 3 transform chains
      - mix_transform_chains_dirichlet: 0. # Dirichlt distribution parameter to sample k=3 mixing convex coeficients. (to be convex along each dimensions, dirichlet coefficents must be > 1.)
      - mix_augmented_with_original: 0. # if strength/severity is greater than 0: final augmented image will be with it original image (given value discribes Beta distribution)
  - singan_augmentation: &singan_augmentation
    <<: *basic_augmentation
    transforms_additional:
      - distilled_singan_augmentation: true

basic_preprocessing_procedure: &basic_preprocessing_procedure
  validset_ratio: 0.2
  testset_ratio: 0.2
  cache: true
  preprocessing:
    - pil_to_tensor
    - normalize
  augmentation_reciepe: *basic_augmentation

mnist_preprocessing:
  <<: *basic_preprocessing_procedure
  normalization_stats : [[0.15, 0.15, 0.15], [0.15, 0.15, 0.15]]

cifar10_preprocessing: &cifar10_preprocessing
  <<: *basic_preprocessing_procedure
  normalization_stats: [[0.491, 0.482, 0.447], [0.247, 0.243, 0.261]]

cifar100_preprocessing:
  <<: *cifar10_preprocessing

imagenet32_prerocessing:
  <<: *basic_preprocessing_procedure
  normalization_stats: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]


...
%YAML 1.2
%TAG !py! tag:yaml.org,2002:python/object:  
---

# Hyper-parameter YAML configuration file
basic_training_params: &basic_ignite_training
  scheduler:
    type: !py!ignite.contrib.handlers.PiecewiseLinear
    eval_args: ["milestones_values"]
    kwargs:
      milestones_values: "[[0, 0.0], [20 * len(trainset), hp['lr']], [hp['epochs'] * len(trainset), 0.0]]"
  # lr_scheduler:
  #   type: !py!deepcv.meta.one_cycle.OneCyclePolicy
  #   kwargs:
  #     base_lr: 1e-4
  #     max_lr: 0.1
  #     base_momentum: 1e-4
  #     max_momentum: 1e-2
  resume_from: ""
  crash_iteration: -1
  validate_every: 1 # Epoch
  checkpoint_every: # Iters
  log_model_grads_every: # Iters
  display_iters: # Iters
  seed: 563454
  deterministic: false
  dist_url: # "env://"
  dist_backend: "" # Set, for example, nccl (torch.distributed.Backend.NCCL) for distributed training using nccl backend

object_detector:
  <<: *basic_ignite_training
  output_path: ""
  epochs: 80
  batch_size: 32
  optimizer_opts: { lr: 0.1, momentum: 0., weight_decay: 0., nesterov: true }
  model:
    act_fn: !py!deepcv.torch.nn.ReLU # evaluated at runtime in python code
    dropout_prob: 0.0
    batch_norm: { affine: true, eps: !!float 1e-05, momentum: 0.07359778246238029 }
    architecture:
        - conv2d: { kernel_size: [5, 5], out_channels: 4, padding: 2 }
        - conv2d: { kernel_size: [5, 5], out_channels: 4, padding: 2 }
        - conv2d: { kernel_size: [5, 5], out_channels: 4, padding: 2 }
        - avg_pooling: [pooling1, { kernel_size: [2, 2], stride: [2, 2]}]
        - conv2d: { kernel_size: [3, 3], out_channels: 16, padding: 1 }
        - conv2d: { kernel_size: [3, 3], out_channels: 16, padding: 1 }
        - avg_pooling: { kernel_size: [2, 2], stride: [2, 2] }
      - siamese1:
        - dense_link: [dense1, { from: pooling1, allow_scaling: true }]
        - conv2d: { kernel_size: [3, 3], out_channels: 32, padding: 1 }
        - conv2d: { kernel_size: [3, 3], out_channels: 32, padding: 1 }
        - avg_pooling: [pooling2, { kernel_size: [2, 2], stride: [2, 2] }]
        - conv2d: { kernel_size: [3, 3], out_channels: 16, padding: 1 }
        - residual_link: { from: dense1, allow_scaling: true }
      - siamese2:
        - conv2d: { kernel_size: [3, 3], out_channels: 16, padding: 1 }
        - avg_pooling: { kernel_size: [2, 2], stride: [2, 2] }
        - conv2d: { kernel_size: [3, 3], out_channels: 16, padding: 1 }
        - conv2d: { kernel_size: [3, 3], out_channels: 32, padding: 1 }
        - conv2d: { kernel_size: [3, 3], out_channels: 32, padding: 1 }
        - conv2d: { kernel_size: [3, 3], out_channels: 32, padding: 1 }
        - dense_link: { from: pooling2 }
        - conv2d: { kernel_size: [3, 3], out_channels: 64, padding: 1 }
      - !py!deepcv.meta.nn.Flatten: null
      - fully_connected: {out_features: 10}


# object_detector_hp_search:
#   cross_validation: false
#   hyperparams:
#     - optimizer_opts.lr: linear([1e-6, 5e-3])
#     - optimizer.momentum: log_linear([1e-8, 5e-3])
#     - optimizer.weight_decay: log_linear([1e-10, 5e-4])
#     - choice:
#       - model.dropout_prob: choice([0., linear([0.1, 0.6])])
#       - model.batch_norm: choice({ affine: true, eps: !!float 1e-05, momentum: 0.07359778246238029 }, null)